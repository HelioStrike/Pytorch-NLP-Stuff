{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1225672\n"
     ]
    }
   ],
   "source": [
    "#Generate text character by character, by looking at Shakespearean\n",
    "\n",
    "#Import modules for preprocessing\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "#Text that our model will be looking at\n",
    "file = unidecode.unidecode(open('./data/shakesphere/text.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Picks a chunk of the text\n",
    "chunk_len = 200\n",
    "\n",
    "def random_chunk():\n",
    "    start = random.randint(0, file_len - chunk_len)\n",
    "    return file[start: start + chunk_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s in the wreck of maidenhood, cannot for all that\\n    dissuade succession, but that they are limed with the twigs that\\n    threatens them. I hope I need not to advise you further; but I\\n    hope your '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here's random_chunk in practice\n",
    "random_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Heres out RNN model. We'll be using an Embedding for encoding, Linear unit unit for decoding and a GRU in between\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1, -1))\n",
    "        out, hidden = self.gru(out.view(1, 1, -1), hidden)\n",
    "        out = self.decoder(out.view(1, -1))\n",
    "        return out, hidden\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converts text to a tensor of numbers\n",
    "def charTensor(inp_str):\n",
    "    out = [all_characters.index(c) for c in inp_str]\n",
    "    return torch.tensor(out).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 17,  14,  21,  21,  24])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#charTensor in practice\n",
    "charTensor(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Picks a random chunk of text and converts into in a tensor\n",
    "def randomTrainSample():\n",
    "    chunk = charTensor(random_chunk())\n",
    "    inp = chunk[:-1]\n",
    "    target = chunk[1:]\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 18,  15,  94,  44,  94,  32,  24,  30,  21,  13,  96,  94,\n",
       "          94,  94,  94,  54,  25,  14,  10,  20,  94,  29,  17,  10,\n",
       "          29,  74,  96,  94,  94,  54,  44,  38,  44,  49,  44,  56,\n",
       "          54,  75,  94,  58,  14,  94,  20,  23,  24,  32,  94,  34,\n",
       "          24,  30,  27,  94,  13,  27,  18,  15,  29,  75,  94,  54,\n",
       "          25,  14,  10,  20,  94,  32,  17,  10,  29,  82,  96,  94,\n",
       "          94,  37,  53,  56,  55,  56,  54,  75,  94,  55,  17,  14,\n",
       "          27,  14,  68,  28,  94,  23,  24,  94,  22,  24,  27,  14,\n",
       "          94,  29,  24,  94,  11,  14,  94,  28,  10,  18,  13,  73,\n",
       "          94,  11,  30,  29,  94,  17,  14,  94,  18,  28,  94,  11,\n",
       "          10,  23,  18,  28,  17,  68,  13,  73,  96,  94,  94,  94,\n",
       "          94,  36,  28,  94,  14,  23,  14,  22,  34,  94,  29,  24,\n",
       "          94,  29,  17,  14,  94,  25,  14,  24,  25,  21,  14,  94,\n",
       "          10,  23,  13,  94,  17,  18,  28,  94,  12,  24,  30,  23,\n",
       "          29,  27,  34,  75,  96,  94,  94,  94,  94,  44,  29,  94,\n",
       "          28,  17,  10,  21,  21,  94,  11,  14,  94,  28,  24,  75,\n",
       "          96,  94,  94,  51,  47,  40,  37]),\n",
       " tensor([ 15,  94,  44,  94,  32,  24,  30,  21,  13,  96,  94,  94,\n",
       "          94,  94,  54,  25,  14,  10,  20,  94,  29,  17,  10,  29,\n",
       "          74,  96,  94,  94,  54,  44,  38,  44,  49,  44,  56,  54,\n",
       "          75,  94,  58,  14,  94,  20,  23,  24,  32,  94,  34,  24,\n",
       "          30,  27,  94,  13,  27,  18,  15,  29,  75,  94,  54,  25,\n",
       "          14,  10,  20,  94,  32,  17,  10,  29,  82,  96,  94,  94,\n",
       "          37,  53,  56,  55,  56,  54,  75,  94,  55,  17,  14,  27,\n",
       "          14,  68,  28,  94,  23,  24,  94,  22,  24,  27,  14,  94,\n",
       "          29,  24,  94,  11,  14,  94,  28,  10,  18,  13,  73,  94,\n",
       "          11,  30,  29,  94,  17,  14,  94,  18,  28,  94,  11,  10,\n",
       "          23,  18,  28,  17,  68,  13,  73,  96,  94,  94,  94,  94,\n",
       "          36,  28,  94,  14,  23,  14,  22,  34,  94,  29,  24,  94,\n",
       "          29,  17,  14,  94,  25,  14,  24,  25,  21,  14,  94,  10,\n",
       "          23,  13,  94,  17,  18,  28,  94,  12,  24,  30,  23,  29,\n",
       "          27,  34,  75,  96,  94,  94,  94,  94,  44,  29,  94,  28,\n",
       "          17,  10,  21,  21,  94,  11,  14,  94,  28,  24,  75,  96,\n",
       "          94,  94,  51,  47,  40,  37,  40]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomTrainSample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training step\n",
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = rnn.initHidden()\n",
    "    prime_input = charTensor(prime_str)\n",
    "    predicted = prime_str\n",
    "    \n",
    "    for p in range(len(prime_str)):\n",
    "        _, hidden = rnn(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = rnn(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = charTensor(predicted_char)\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trains the model\n",
    "def train(inp, target):\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    loss = 0\n",
    "    for c in range(chunk_len - 1):\n",
    "        output, hidden = rnn(inp[c], hidden)\n",
    "        loss += criterion(output, torch.tensor([target[c]]).long())\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data[0]/chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyper-parameters\n",
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "input_size = output_size = n_characters\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, output_size, n_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "S[%\"^\"G_]bhRPkO\\R9zrG~\"_YMc/u|fQV)M~7]N%R\"Z\n",
      "\n",
      "Epoch 100\n",
      "Wh[ sore fot pigheed ns thell ors me and spars sen ges oft hinme stset bend that bef ang, wopre am fow\n",
      "\n",
      "Epoch 200\n",
      "Wher, to rownd poring cotrer, wot il yuth thats cadis to whe ar ou and wour theur oh tharn thee we ver\n",
      "\n",
      "Epoch 300\n",
      "What sore did?\n",
      "  TMARVDSe. If be hourip bot be my frack my grivy sep be dniser' son bod and moress\n",
      "   \n",
      "\n",
      "Epoch 400\n",
      "Whill\n",
      "               Weethe?                                                                          \n",
      "\n",
      "Epoch 500\n",
      "Whe siser. Dring.\n",
      "   Noin the saof the she a ellove my so ands, ming and strrais a bus poresestless de\n",
      "\n",
      "Epoch 600\n",
      "Whav'd mear'd I hey\n",
      "        in the reave a as namat aceintts the causing that ment trom a gorn\n",
      "    Thy\n",
      "\n",
      "Epoch 700\n",
      "Who his breast, pears beabt in man falll makinges; cang taken maket grame.\n",
      "  Hargel sall her nok sario\n",
      "\n",
      "Epoch 800\n",
      "Whil, [and theare in EPERSAY FERMIPHOLUS MEOND SAYYRALA, I never our hise is not on CORIOLANT OUTHESTR\n",
      "\n",
      "Epoch 900\n",
      "Whert truse woudds not the\n",
      "          ound the not by fallonesty for bodst and the when tient of that w\n",
      "\n",
      "Epoch 1000\n",
      "Why bectus age and me shrownedy sprith this shoolus one\n",
      "    And the some prown offeet from\n",
      "    I speak\n",
      "\n",
      "Epoch 1100\n",
      "Wh where thy shall lilfinfess so dear your.\n",
      "                                              honenst Cand\n",
      "\n",
      "Epoch 1200\n",
      "Wh had the so so thearter bougient!\n",
      "  Jould strave Life.\n",
      "  For in  ive, yound may;\n",
      "\n",
      "              and \n",
      "\n",
      "Epoch 1300\n",
      "Why beaus, of make have comeny loursed's\n",
      "    where of the stall\n",
      "    And I have freses your be devitrat\n",
      "\n",
      "Epoch 1400\n",
      "Wher to my depreshould not lince of\n",
      "  'Tund here so mett ententen hous,\n",
      "    I, comspeclust sprcice\n",
      "   \n",
      "\n",
      "Epoch 1500\n",
      "Wher lover and hous being.\n",
      "    When cangers, where oranst.\n",
      "  Gown inis lie, see warous sardst it the l\n",
      "\n",
      "Epoch 1600\n",
      "Whert, vongoust at declown, sweet thy bay of the this marde\n",
      "    We th' and have evers thy look. Park I\n",
      "\n",
      "Epoch 1700\n",
      "When thy wur.\n",
      "  Will the shord, Rald why cours\n",
      "  The but wel of the mood with me is thould findilling \n",
      "\n",
      "Epoch 1800\n",
      "Wher should here\n",
      "    This say to the where to me to hather my a metter meaties to ther as and stender.\n",
      "\n",
      "Epoch 1900\n",
      "Whing carrows pair in givis hum stord hut so dise\n",
      "    Prock some of the betlient ween the poling on to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "loss_avg = 0\n",
    "all_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    loss = train(*randomTrainSample())\n",
    "    loss_avg += loss\n",
    "    \n",
    "    if(epoch%print_every == 0):\n",
    "        print(\"Epoch\", epoch)\n",
    "        print(evaluate('Wh', predict_len=100) + '\\n')\n",
    "   \n",
    "    if(epoch%plot_every == 0):\n",
    "        all_losses.append(loss)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
